import hashlib
import json
from datetime import datetime
from typing import List, Tuple, Dict
import utils
import os
import re


class ICAJSONGenerator:
    def __init__(self, input_dir: str, output_dir: str):
        """
        Classe que cria JSONs contendo os textos dos artigos a partir do
        texto extraido do arquivo, em .txt
        """
        print('Inst√¢ncia criada!')
        self.input_dir = os.path.join(os.getcwd(), input_dir)
        self.output_dir = os.path.join(os.getcwd(), output_dir)
        print(f'Caminho de entrada: {self.input_dir}')
        print(f'Caminho de saida: {self.output_dir}')

    def get_caminhos(self) -> list[str]:
        """Retorna uma lista com os caminhos completos de todos os arquivos dentro de um diret√≥rio."""
        extensoes = [".txt"]
        caminhos = []
        for raiz, _, arquivos in os.walk(self.input_dir):
            for arquivo in arquivos:
                if extensoes:
                    # verifica se o arquivo termina com uma das extens√µes permitidas
                    if not arquivo.lower().endswith(tuple(extensoes)):
                        continue
                caminhos.append(os.path.join(raiz, arquivo))
        return caminhos

    def process_documents(self):
        print('-'*40)
        print('INICIANDO PROCESSO DE CRIA√á√ÇO DE JSONS')
        print(f'Busca por caminhos iniciada no diret√≥rio: {self.input_dir}')
        print('Caminhos obtidos: ')
        print(self.get_caminhos())
        for i, file_path in enumerate(self.get_caminhos()):
            print('-'*20)
            print(f'Repeti√ß√£o {i}')
            print(f'Caminho de arquivo: {file_path}')

            # Textos separados por p√°gina
            with open(file_path, 'r', encoding='utf-8') as arquivo:
                textos = arquivo.read().split('--- P√ÅGINA ---')
            print(textos)
            primeira_pagina = textos[0]
            # revogada = get_ica_revogado(primeira_pagina)

            numero_ica = extrair_numero_ica(file_path)

            # Extrair data de publica√ß√£o (voc√™ pode criar uma fun√ß√£o espec√≠fica para isso)
            data_publicacao = extrair_data_publicacao(primeira_pagina)

            artigos_estruturados = extrair_artigos_estruturados(textos, numero_ica, data_publicacao)

            salvar_artigos_json(
                artigos_estruturados,
                os.path.join(self.output_dir, fr"{numero_ica}.json"),
                'legivel'
            )

            print('-'*20)
        print('PROCESSO DE CRIA√á√ÇO DE JSONS ENCERRADO')
        print('-'*40)

def get_ica_revogado(texto: str):
    # print(texto)
    # print(texto.__contains__('Art'))
    # print(type(texto))
    print('-'*40)
    print('INICIANDO PROCESSO DE BUSCA POR REVOGA√á√ÉO')
    art_revogacao = None
    for num_art, texto_art in get_articles_simplificado(texto, True):
        print('-'*20)
        print(f'Artigo: {num_art}')
        print(f'Conte√∫do: \n{texto_art[:min(len(texto_art), 400)]}')  # limita at√© 400 caracteres (polui√ß√£o visual)

        if any(value.lower() in texto_art.lower() for value in ['Revoga', 'Revogado', 'Revogou']):
            print(f'Aqui √© o artigo que revoga!!!! no artigo {num_art}')
            art_revogacao = (num_art, texto_art)
        print('-'*20)

    if not art_revogacao:
        print('ICA analisado n√£o revoga nenhum outro ICA')
        print('-'*40)
        return None

    padrao = re.compile(
        r"""
        [Rr]evog(?:ar|a-se)\s+a\s+Portaria\s+          # in√≠cio da frase
        (?P<orgao>[A-Z√á√ï√â√ä√Ç]+\s*)?                    # √≥rg√£o (ex: DECEA)
        n[¬∞¬∫]?\s*                                     # s√≠mbolo de n√∫mero (n¬∞, n¬∫, n2 etc.)
        (?P<numero>[\d]+(?:\/[A-Z0-9]+)?)             # n√∫mero e poss√≠vel sufixo (801/ATAN3)
        ,?\s*de\s*(?P<data>[\d]{1,2}\s+de\s+\w+\s+de\s+\d{4})  # data
        (?:.*?(?:publicada\s+no.*?(?P<boletim>BCA|Boletim.*?)\s*(?:n[¬∞¬∫]?\s*[\d]+)?.*?)?)?
        [\.;]?                                         # final opcional
        """,
        re.VERBOSE
    )

    texto = texto.replace('\n','')
    resultados = []
    for match in padrao.finditer(texto):
        resultados.append({
            "orgao": match.group("orgao"),
            "numero": match.group("numero"),
            "data": match.group("data"),
            "boletim": match.group("boletim")
        })

    for result in resultados:
        print(result)
    return resultados


def get_articles_simplificado(texto: str, debug=False) -> list[str]:
    """
    Extrai todos os artigos (Art. X¬∞, Artigo X, etc.) de um documento textual.
    Retorna lista de tuplas: (numero_artigo, texto_artigo).
    """
    # texto = limpar_texto_ocr(texto)

    # Express√£o para capturar "Art." ou "Artigo", seguidos de n√∫mero e s√≠mbolo opcional ¬∫/¬∞
    padrao = r'(?m)^(Art(?:igo)?\.?\s*\d{1,3}\s*[¬∫¬∞]?)'

    matches = list(re.finditer(padrao, texto))

    if debug:
        print(f"üîç {len(matches)} artigos encontrados")
        for m in matches:
            print(f"  -> '{m.group(1)}' (posi√ß√£o {m.start()})")

    artigos = []
    for i, match in enumerate(matches):
        inicio = match.end()
        fim = matches[i + 1].start() if i + 1 < len(matches) else len(texto)
        numero = match.group(1).strip()
        conteudo = texto[inicio:fim].strip()
        artigos.append((numero, conteudo))

    return artigos


def extrair_numero_ica(caminho_completo: str) -> str:
    """
    Extrai o n√∫mero do ICA do nome do arquivo.
    """
    nome_arquivo = os.path.basename(caminho_completo)
    print(nome_arquivo)
    nome_sem_ext = os.path.splitext(nome_arquivo)[0]
    print(nome_sem_ext)
    return nome_sem_ext


def extrair_data_publicacao(texto: str) -> str:
    """
    Extrai a data de publica√ß√£o do documento.
    """
    # Padr√£o: "DD DE MMMM DE AAAA"
    padrao = re.compile(r'(\d{1,2})\s+[Dd][Ee]\s+(\w+)\s+[Dd][Ee]\s+(\d{4})')
    match = padrao.search(texto)

    if match:
        dia = match.group(1).zfill(2)
        mes_texto = match.group(2).lower()
        ano = match.group(3)

        meses = {
            'janeiro': '01', 'fevereiro': '02', 'mar√ßo': '03', 'abril': '04',
            'maio': '05', 'junho': '06', 'julho': '07', 'agosto': '08',
            'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'
        }

        mes = meses.get(mes_texto, '01')
        return f"{dia}-{mes}-{ano}"

    return datetime.now().strftime("%d-%m-%Y")


def extrair_artigos_estruturados(textos: List[str], numero_ica: str, data_publicacao: str) -> List[Dict]:
    """
    Extrai todos os artigos de um documento ICA com seu contexto hier√°rquico completo.

    Args:
        textos: Lista de strings, cada uma representando o texto de uma p√°gina
        numero_ica: N√∫mero do ICA (ex: "ICA 96-1")
        data_publicacao: Data de publica√ß√£o no formato "DD-MM-AAAA"

    Returns:
        Lista de dicion√°rios com a estrutura padronizada dos artigos
    """

    # Juntar todas as p√°ginas em um √∫nico texto
    texto_completo = "\n".join(textos)

    # PADR√ÉO MELHORADO: aceita I, l, 1, | (pipe) e varia√ß√µes
    padrao_titulo = re.compile(
        r'(?m)^T[√çIi|l1]TULO\s*([IVXLCDM|]+|[0-9]+)\s*[-‚Äì‚Äî]?\s*(.*?)$',
        re.IGNORECASE
    )

    padrao_capitulo = re.compile(
        r'(?m)^CAP[√çIi|l1]TULO\s*([IVXLCDM|]+|[0-9]+)\s*[-‚Äì‚Äî]?\s*(.*?)$',
        re.IGNORECASE
    )

    padrao_secao = re.compile(
        r'(?m)^SE[CcGg][√á√ßCcGg]?[√É√£AaOo][Oo]?\s*([IVXLCDM|]+|[0-9]+)\s*[-‚Äì‚Äî]?\s*(.*?)$',
        re.IGNORECASE
    )

    padrao_subsecao = re.compile(
        r'(?m)^SUBSE[CcGg][√á√ßCcGg]?[√É√£AaOo][Oo]?\s*([IVXLCDM|]+|[0-9]+)\s*[-‚Äì‚Äî]?\s*(.*?)$',
        re.IGNORECASE
    )

    # Padr√£o para identificar artigos (mant√©m o seu)
    padrao_artigo = re.compile(
        r'(?m)^(Art\.?\s*\d{1,4}[¬∫¬∫¬∫¬∞]?\.?|Artigo\s+\d{1,4}[¬∫¬∫¬∫¬∞]?\.?)',
        re.IGNORECASE
    )

    # Debug: Verificar se est√° encontrando
    print(f'\n{"=" * 50}')
    print(f'AN√ÅLISE DO DOCUMENTO: {numero_ica}')
    print(f'{"=" * 50}')

    # Encontrar todas as ocorr√™ncias
    titulos = [(m.start(), m.group(1), m.group(2).strip()) for m in padrao_titulo.finditer(texto_completo)]
    print(f'\nüìå T√≠tulos extra√≠dos ({len(titulos)}):')
    for pos, num, nome in titulos[:5]:  # Mostra apenas os 5 primeiros
        print(f'   Posi√ß√£o {pos}: T√çTULO {num} - {nome[:50]}...')

    capitulos = [(m.start(), m.group(1), m.group(2).strip()) for m in padrao_capitulo.finditer(texto_completo)]
    print(f'\nüìå Cap√≠tulos extra√≠dos ({len(capitulos)}):')
    for pos, num, nome in capitulos[:5]:
        print(f'   Posi√ß√£o {pos}: CAP√çTULO {num} - {nome[:50]}...')

    secoes = [(m.start(), m.group(1), m.group(2).strip()) for m in padrao_secao.finditer(texto_completo)]
    print(f'\nüìå Se√ß√µes extra√≠das ({len(secoes)}):')
    for pos, num, nome in secoes[:5]:
        print(f'   Posi√ß√£o {pos}: SE√á√ÉO {num} - {nome[:50]}...')

    subsecoes = [(m.start(), m.group(1), m.group(2).strip()) for m in padrao_subsecao.finditer(texto_completo)]
    print(f'\nüìå Subse√ß√µes extra√≠das ({len(subsecoes)}):')
    for pos, num, nome in subsecoes[:5]:
        print(f'   Posi√ß√£o {pos}: SUBSE√á√ÉO {num} - {nome[:50]}...')

    # Encontrar todos os artigos
    matches_artigos = list(padrao_artigo.finditer(texto_completo))
    print(f'\nüìå Artigos encontrados: {len(matches_artigos)}')

    artigos_estruturados = []
    data_acesso = datetime.now().strftime("%d-%m-%Y")

    for i, match in enumerate(matches_artigos):
        # Extrair n√∫mero do artigo
        numero_artigo_raw = match.group(1).strip()
        # Normalizar o n√∫mero do artigo
        numero_artigo = re.sub(r'[¬∫¬∫¬∞]', '¬∫', numero_artigo_raw)
        numero_artigo = re.sub(r'\s+', ' ', numero_artigo)
        if not numero_artigo.endswith('.'):
            numero_artigo = numero_artigo.rstrip('.')

        # Determinar in√≠cio e fim do texto do artigo
        inicio_artigo = match.end()
        fim_artigo = matches_artigos[i + 1].start() if i + 1 < len(matches_artigos) else len(texto_completo)

        # Extrair texto do artigo
        texto_artigo = texto_completo[inicio_artigo:fim_artigo].strip()

        # Limpar excesso de espa√ßos e quebras de linha
        texto_artigo = re.sub(r'\s+', ' ', texto_artigo)
        texto_artigo = texto_artigo.strip()

        # Concatenar n√∫mero do artigo com o texto
        texto_completo_artigo = f"{numero_artigo} {texto_artigo}"

        # Determinar o contexto hier√°rquico
        posicao_artigo = match.start()

        # Encontrar o contexto atual
        titulo_atual = None
        capitulo_atual = None
        secao_atual = None
        subsecao_atual = None

        # T√≠tulo
        for pos, num, nome in reversed(titulos):
            if pos < posicao_artigo:
                titulo_atual = f"T√çTULO {num}" + (f" - {nome}" if nome else "")
                break

        # Cap√≠tulo
        for pos, num, nome in reversed(capitulos):
            if pos < posicao_artigo:
                capitulo_atual = f"CAP√çTULO {num}" + (f" - {nome}" if nome else "")
                break

        # Se√ß√£o
        for pos, num, nome in reversed(secoes):
            if pos < posicao_artigo:
                secao_atual = f"SE√á√ÉO {num}" + (f" - {nome}" if nome else "")
                break

        # Subse√ß√£o
        for pos, num, nome in reversed(subsecoes):
            if pos < posicao_artigo:
                subsecao_atual = f"SUBSE√á√ÉO {num}" + (f" - {nome}" if nome else "")
                break

        # Gerar ID √∫nico
        # TODO N√£o ler os primeiros artigos, eles n√£o servem pra salvar informa√ß√µes
        chave_id = f"{numero_ica}_{numero_artigo}"
        id_artigo = hashlib.md5(chave_id.encode('utf-8')).hexdigest()

        # Construir estrutura do artigo
        artigo_estruturado = {
            "id": id_artigo,
            "texto": texto_completo_artigo,
            "metadados": {
                "tipo_documento": "ICA",
                "nome": numero_ica,
                "artigo": numero_artigo,
                "data_publicacao": data_publicacao,
                "data_acesso": data_acesso,
                "contexto": {
                    "titulo": titulo_atual,
                    "capitulo": capitulo_atual,
                    "secao": secao_atual,
                    "subsecao": subsecao_atual
                }
            }
        }

        artigos_estruturados.append(artigo_estruturado)

    return artigos_estruturados


def salvar_artigos_json(artigos: List[Dict], caminho_saida: str, formato: str = 'compacto'):
    """
    Salva a lista de artigos em um arquivo JSON.

    Args:
        artigos: Lista de dicion√°rios com os artigos estruturados
        caminho_saida: Caminho completo do arquivo de sa√≠da
        formato: 'compacto', 'legivel' ou 'estruturado'
    """
    # Garantir que o diret√≥rio de sa√≠da existe
    diretorio = os.path.dirname(caminho_saida)
    if diretorio and not os.path.exists(diretorio):
        os.makedirs(diretorio)
    if formato == 'compacto':
        # Formato compacto (sem indenta√ß√£o, economiza espa√ßo)
        with open(caminho_saida, 'w', encoding='utf-8') as f:
            json.dump(artigos, f, ensure_ascii=False, separators=(',', ':'))

    elif formato == 'legivel':
        # Formato leg√≠vel (com indenta√ß√£o)
        with open(caminho_saida, 'w', encoding='utf-8') as f:
            json.dump(artigos, f, ensure_ascii=False, indent=2)

    elif formato == 'estruturado':
        # Formato estruturado com metadados do documento
        documento_completo = {
            "metadados_documento": {
                "total_artigos": len(artigos),
                "data_extracao": datetime.now().strftime("%d-%m-%Y %H:%M:%S"),
                "nome_arquivo_origem": os.path.basename(caminho_saida).replace('_artigos.json', '.pdf')
            },
            "artigos": artigos
        }

        with open(caminho_saida, 'w', encoding='utf-8') as f:
            json.dump(documento_completo, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ {len(artigos)} artigos salvos em: {caminho_saida}")


if __name__ == '__main__':
    utils.garantir_cwd_para("Repositorio-Semantico")

    # TODO  criar um sistema de compara√ß√£o entre a data de inicio de vigor do
    #  ICA pelo nome do arquivo e a data no texto mesmo

    ica_json_generator = ICAJSONGenerator(
        input_dir=r'ICA_Extractor\textos_extraidos',
        output_dir=r"JSONs\ICA"
    )
    ica_json_generator.process_documents()



